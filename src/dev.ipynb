{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f218774d-adf4-41da-8ac3-605de7141f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "path = \"../dataset/topiocqa_train_rel_label.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1d23b6-879b-4364-8190-346955e9a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c67be8-314e-40a6-942f-dca322ddb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = data[0]\n",
    "e_dict = json.loads(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703424bc-f57d-40a7-911f-cdec17cd2e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1-2-1',\n",
       " 'query': 'was the battle fought in australia?',\n",
       " 'rel_query': \"what was australia's contribution to the battle of normandy?\",\n",
       " 'rel_label': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edab61b6-ab9b-4484-aefa-80d000cd627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../bertmodel were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "bert_path = \"../../bertmodel\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "model = BertModel.from_pretrained(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b011391e-c7ba-46a7-9b0e-6648aaa662df",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(e_dict['query'], return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e8ecae-21c9-4ceb-8ace-bb7f796e216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2001, 1996, 2645, 4061, 1999, 2660, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a310e3c0-83cc-4601-9630-3b7580d98384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2001, 1996, 2645, 4061, 1999, 2660, 1029,  102]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6158b443-fe60-4e11-b459-e9b3f2eaf7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_seq_to_same_length(input_ids, max_pad_length, pad_token = 0):\n",
    "    padding_length = max_pad_length - len(input_ids)\n",
    "    padding_ids = [pad_token] * padding_length\n",
    "    attention_mask = []\n",
    "\n",
    "    if padding_length <= 0:\n",
    "        attention_mask = [1] * max_pad_length\n",
    "        input_ids = input_ids[:max_pad_length]\n",
    "    else:\n",
    "        attention_mask = [1] * len(input_ids) + [0] * padding_length\n",
    "        input_ids = input_ids + padding_ids\n",
    "            \n",
    "    assert len(input_ids) == max_pad_length\n",
    "    assert len(attention_mask) == max_pad_length\n",
    "  \n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe740f0-e117-4160-a8ab-e016fb2252b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "def padding(input_dict: dict, max_pad_len: int, pad_token=0):\n",
    "    input_ids = input_dict['input_ids'].reshape(-1,)\n",
    "    attention_mask = input_dict['attention_mask'].reshape(-1,)\n",
    "    padding_len = max_pad_len - len(input_ids)\n",
    "    padding_ids = torch.tensor([pad_token] * padding_len)\n",
    "    input_ids = torch.cat((input_ids, padding_ids), 0)\n",
    "    attention_mask = torch.cat((attention_mask, padding_ids), 0)\n",
    "    return {'input_ids': input_ids.long(), 'attention_mask': attention_mask.long()}\n",
    "\n",
    "\n",
    "class CRDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, fpath: str, bpath: str):\n",
    "        \"\"\" \n",
    "        fpath: dataset file path\n",
    "        bpath: path stored BertModel and BertTokenizer\n",
    "        \"\"\"\n",
    "        tokened = []\n",
    "        max_token_len_q, max_token_len_r = 0, 0\n",
    "        tokenizer = BertTokenizer.from_pretrained(bpath)\n",
    "        with open(fpath, 'r') as f:\n",
    "            lines = f.readlines()[:5]\n",
    "        \n",
    "        for line in lines:\n",
    "            l_dict = json.loads(line)\n",
    "            \"\"\"\n",
    "            {'id': , 'query': str, 'rel_query': str, 'rel_label': int}\n",
    "            \"\"\"\n",
    "            if l_dict['rel_label'] == 1:\n",
    "                q = tokenizer(l_dict['query'], return_tensors='pt')\n",
    "                r = tokenizer(l_dict['rel_query'], return_tensors='pt')\n",
    "                q_len = q['input_ids'].size(1)\n",
    "                r_len = r['input_ids'].size(1)\n",
    "                tokened.append({\n",
    "                    'query': q,\n",
    "                    'rel_query': r\n",
    "                })\n",
    "                max_token_len_q = q_len if max_token_len_q < q_len else max_token_len_q\n",
    "                max_token_len_r = r_len if max_token_len_r < r_len else max_token_len_r\n",
    "        \n",
    "        self.q_data, self.r_data = [], []\n",
    "        for each in tokened:\n",
    "            self.q_data.append(padding(each['query'], max_token_len_q))\n",
    "            self.r_data.append(padding(each['rel_query'], max_token_len_r))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.q_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.q_data[idx], self.r_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3a5b71-0d45-49b0-ba14-8b8f3526f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../dataset/topiocqa_train_rel_label.json\"\n",
    "bert_path = \"../../bertmodel\"\n",
    "a = CRDataset(path, bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21a21eb-3312-4542-83ba-2111924efc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(a, batch_size=64, shuffle=True)\n",
    "for i in dataloader:\n",
    "    q, r = i[0], i[1]\n",
    "    o1, o2 = model(**q), model(**r)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b84e3462-de4c-4dd5-8957-e06868749c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0637,  0.2949, -0.1112,  ..., -0.1946,  0.5498,  0.2801],\n",
       "         [-0.0561, -0.3334, -0.4881,  ..., -0.1952,  0.7908, -0.4225],\n",
       "         [ 0.5326, -0.1612,  0.1917,  ...,  0.1072,  0.1583,  0.3446],\n",
       "         ...,\n",
       "         [-0.0290, -0.2623, -1.0503,  ...,  0.2627,  0.4326, -0.6171],\n",
       "         [ 0.6830,  0.0588, -0.3071,  ..., -0.0451, -0.6085, -0.1968],\n",
       "         [ 0.2224,  0.3453,  0.1382,  ...,  0.3099,  0.4229, -0.1855]],\n",
       "\n",
       "        [[-0.3621, -0.1404, -0.3945,  ..., -0.2740,  0.3580,  0.4217],\n",
       "         [-0.0554, -1.2396, -0.3728,  ...,  0.1045,  0.2866,  0.3871],\n",
       "         [-0.8824, -1.0056, -0.4195,  ...,  0.0063, -0.0768, -0.4187],\n",
       "         ...,\n",
       "         [-0.3328,  0.3367, -0.3125,  ..., -0.2629, -0.4598, -0.1589],\n",
       "         [-0.1430, -0.7991, -0.5618,  ..., -0.0060,  0.5460, -0.4408],\n",
       "         [ 0.6047,  0.0930, -0.4777,  ..., -0.0476, -0.5917, -0.3552]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9247, -0.4866, -0.7933,  ..., -0.5986, -0.7477,  0.9310],\n",
       "        [-0.8868, -0.3425, -0.7206,  ..., -0.6039, -0.6785,  0.8944]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c6fd382-20b3-4f89-91c4-a9370b586d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2001, 1996, 2645, 4061, 1999, 2660, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1fc58ea-674c-4ed3-afe6-21b37ba15b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 29])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b4ae4-5078-4fa1-8e70-7db82e5e4626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.x Kernel",
   "language": "python",
   "name": "python_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
